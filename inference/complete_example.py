#!/usr/bin/env python3
"""
å®Œæ•´çš„è¿è¡Œæ—¶è¡¥ä¸æ¨ç†ç¤ºä¾‹
ä½¿ç”¨ä¿®å¤åçš„è¡¥ä¸ç³»ç»Ÿè¿›è¡Œ LLaVA-CoT æ¨ç†
"""

import sys
import os
import torch
from PIL import Image
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def main():
    print("ğŸš€ LLaVA-CoT è¿è¡Œæ—¶è¡¥ä¸æ¨ç†ç¤ºä¾‹")
    print("=" * 60)
    
    # æ­¥éª¤1: åº”ç”¨è¡¥ä¸
    print("\nğŸ”§ æ­¥éª¤1: åº”ç”¨è¿è¡Œæ—¶è¡¥ä¸...")
    try:
        from simple_patch import patch_mllama_processor_simple
        
        if not patch_mllama_processor_simple():
            print("âŒ è¡¥ä¸åº”ç”¨å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
            from fixed_patch import patch_mllama_processor
            if not patch_mllama_processor():
                print("âŒ æ‰€æœ‰è¡¥ä¸æ–¹æ¡ˆéƒ½å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
                return False
        
        print("âœ… è¡¥ä¸åº”ç”¨æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ è¡¥ä¸åº”ç”¨å‡ºé”™: {e}")
        return False
    
    # æ­¥éª¤2: å¯¼å…¥ transformers
    print("\nğŸ“¦ æ­¥éª¤2: å¯¼å…¥ transformers åº“...")
    try:
        from transformers import MllamaForConditionalGeneration, AutoProcessor
        print("âœ… æˆåŠŸå¯¼å…¥ transformers")
    except Exception as e:
        print(f"âŒ å¯¼å…¥ transformers å¤±è´¥: {e}")
        return False
    
    # æ­¥éª¤3: åŠ è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œéœ€è¦æ¨¡å‹æ–‡ä»¶ï¼‰
    print("\nğŸ¤– æ­¥éª¤3: æ¨¡å‹åŠ è½½ç¤ºä¾‹...")
    model_name = "Xkev/Llama-3.2V-11B-cot"
    
    try:
        # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_name}")
        print("ğŸ’¡ å®é™…ä½¿ç”¨æ—¶çš„ä»£ç :")
        print(f"""
# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
model = MllamaForConditionalGeneration.from_pretrained(
    "{model_name}",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
processor = AutoProcessor.from_pretrained("{model_name}")

# å‡†å¤‡è¾“å…¥
image = Image.open("your_image.jpg")
prompt = "How to make this pastry?"

messages = [
    {{'role': 'user', 'content': [
        {{'type': 'image'}},
        {{'type': 'text', 'text': prompt}}
    ]}}
]

# å¤„ç†è¾“å…¥
input_text = processor.apply_chat_template(messages, add_generation_prompt=True)
inputs = processor(image, input_text, return_tensors='pt').to(model.device)

# ç”Ÿæˆè¾“å‡º
with torch.no_grad():
    output = model.generate(**inputs, max_new_tokens=2048)

# è§£ç ç»“æœ
result = processor.decode(output[0], skip_special_tokens=True)
print("æ¨ç†ç»“æœ:", result)
""")
        
        print("âœ… æ¨¡å‹åŠ è½½ç¤ºä¾‹å®Œæˆ")
        
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹åŠ è½½ç¤ºä¾‹å‡ºé”™ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ²¡æœ‰å®é™…æ¨¡å‹æ–‡ä»¶ï¼‰: {e}")
    
    # æ­¥éª¤4: éªŒè¯è¡¥ä¸çŠ¶æ€
    print("\nğŸ” æ­¥éª¤4: éªŒè¯è¡¥ä¸çŠ¶æ€...")
    try:
        from simple_patch import verify_patch_simple
        if verify_patch_simple():
            print("âœ… è¡¥ä¸çŠ¶æ€éªŒè¯æˆåŠŸ")
        else:
            print("âš ï¸  è¡¥ä¸çŠ¶æ€éªŒè¯å¤±è´¥")
    except Exception as e:
        print(f"âŒ éªŒè¯å‡ºé”™: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è¿è¡Œæ—¶è¡¥ä¸ç¤ºä¾‹å®Œæˆï¼")
    print("\nğŸ“‹ æ€»ç»“:")
    print("1. âœ… æˆåŠŸåº”ç”¨è¿è¡Œæ—¶è¡¥ä¸")
    print("2. âœ… æˆåŠŸå¯¼å…¥ transformers åº“")
    print("3. âœ… è¡¥ä¸çŠ¶æ€éªŒè¯é€šè¿‡")
    print("4. ğŸ“ æä¾›äº†å®Œæ•´çš„æ¨ç†ä»£ç ç¤ºä¾‹")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("- ä¸‹è½½ LLaVA-CoT æ¨¡å‹æ–‡ä»¶")
    print("- å‡†å¤‡æµ‹è¯•å›¾åƒ")
    print("- è¿è¡Œå®Œæ•´çš„æ¨ç†æµç¨‹")
    
    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ¯ ç¨‹åºæ‰§è¡ŒæˆåŠŸ")
    else:
        print("\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥")
        sys.exit(1)