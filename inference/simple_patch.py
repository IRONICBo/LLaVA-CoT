#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆè¿è¡Œæ—¶è¡¥ä¸ - è§£å†³ç›¸å¯¹å¯¼å…¥é—®é¢˜
ç›´æ¥æ›¿æ¢æ¨¡å—å†…å®¹è€Œä¸æ˜¯åŠ¨æ€åŠ è½½
"""

import sys
import importlib
from pathlib import Path

def patch_mllama_processor_simple():
    """
    ç®€åŒ–ç‰ˆè¡¥ä¸æ–¹æ³• - ç›´æ¥ä¿®æ”¹å·²å¯¼å…¥çš„æ¨¡å—
    """
    try:
        # é¦–å…ˆç¡®ä¿ transformers å·²å¯¼å…¥
        import transformers
        print(f"âœ… transformers ç‰ˆæœ¬: {transformers.__version__}")
        
        # å¯¼å…¥ç›®æ ‡æ¨¡å—
        from transformers.models.mllama import processing_mllama as target_module
        print("âœ… æˆåŠŸå¯¼å…¥ç›®æ ‡æ¨¡å—")
        
        # è¯»å–è‡ªå®šä¹‰å¤„ç†å™¨æ–‡ä»¶å†…å®¹
        current_dir = Path(__file__).parent
        custom_file = current_dir / "processing_mllama.py"
        
        if not custom_file.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è‡ªå®šä¹‰å¤„ç†å™¨æ–‡ä»¶: {custom_file}")
        
        # è¯»å–å¹¶ä¿®æ”¹è‡ªå®šä¹‰æ–‡ä»¶å†…å®¹ï¼Œæ›¿æ¢ç›¸å¯¹å¯¼å…¥
        with open(custom_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢ç›¸å¯¹å¯¼å…¥ä¸ºç»å¯¹å¯¼å…¥
        content = content.replace(
            "from ...feature_extraction_utils import BatchFeature",
            "from transformers.feature_extraction_utils import BatchFeature"
        )
        content = content.replace(
            "from ...image_utils import ImageInput",
            "from transformers.image_utils import ImageInput"
        )
        content = content.replace(
            "from ...processing_utils import ImagesKwargs, ProcessingKwargs, ProcessorMixin, Unpack",
            "from transformers.processing_utils import ImagesKwargs, ProcessingKwargs, ProcessorMixin, Unpack"
        )
        content = content.replace(
            "from ...tokenization_utils_base import",
            "from transformers.tokenization_utils_base import"
        )
        content = content.replace(
            "from .image_processing_mllama import make_list_of_images",
            "from transformers.models.mllama.image_processing_mllama import make_list_of_images"
        )
        
        # åˆ›å»ºä¸´æ—¶æ¨¡å—
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as tmp_file:
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        try:
            # åŠ¨æ€åŠ è½½ä¿®æ”¹åçš„æ¨¡å—
            import importlib.util
            spec = importlib.util.spec_from_file_location("custom_processing_mllama", tmp_file_path)
            custom_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(custom_module)
            
            print("âœ… æˆåŠŸåŠ è½½è‡ªå®šä¹‰æ¨¡å—")
            
            # å¤‡ä»½åŸå§‹å±æ€§
            backup = {}
            for attr_name in dir(target_module):
                if not attr_name.startswith('_'):
                    backup[attr_name] = getattr(target_module, attr_name)
            
            # åº”ç”¨è¡¥ä¸
            patch_count = 0
            for attr_name in dir(custom_module):
                if not attr_name.startswith('_'):
                    setattr(target_module, attr_name, getattr(custom_module, attr_name))
                    patch_count += 1
            
            # æ ‡è®°å·²è¡¥ä¸
            setattr(target_module, '_runtime_patched', True)
            setattr(target_module, '_backup', backup)
            
            print(f"âœ… æˆåŠŸåº”ç”¨è¡¥ä¸ ({patch_count} ä¸ªå±æ€§)")
            return True
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(tmp_file_path)
            except:
                pass
                
    except Exception as e:
        print(f"âŒ è¡¥ä¸åº”ç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def restore_mllama_processor_simple():
    """æ¢å¤åŸå§‹å¤„ç†å™¨"""
    try:
        from transformers.models.mllama import processing_mllama as target_module
        
        if not hasattr(target_module, '_runtime_patched'):
            print("âš ï¸  æ¨¡å—æœªè¢«è¡¥ä¸è¿‡")
            return False
        
        if not hasattr(target_module, '_backup'):
            print("âš ï¸  æ²¡æœ‰å¤‡ä»½æ•°æ®")
            return False
        
        backup = getattr(target_module, '_backup')
        
        # æ¢å¤æ‰€æœ‰å±æ€§
        for attr_name, original_value in backup.items():
            setattr(target_module, attr_name, original_value)
        
        # æ¸…ç†æ ‡è®°
        delattr(target_module, '_runtime_patched')
        delattr(target_module, '_backup')
        
        print("âœ… æˆåŠŸæ¢å¤åŸå§‹æ¨¡å—")
        return True
        
    except Exception as e:
        print(f"âŒ æ¢å¤å¤±è´¥: {e}")
        return False

def verify_patch_simple():
    """éªŒè¯è¡¥ä¸çŠ¶æ€"""
    try:
        from transformers.models.mllama import processing_mllama as target_module
        is_patched = hasattr(target_module, '_runtime_patched')
        print(f"ğŸ“Š è¡¥ä¸çŠ¶æ€: {'å·²åº”ç”¨' if is_patched else 'æœªåº”ç”¨'}")
        return is_patched
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ”§ æµ‹è¯•ç®€åŒ–ç‰ˆè¡¥ä¸...")
    
    # åº”ç”¨è¡¥ä¸
    if patch_mllama_processor_simple():
        # éªŒè¯è¡¥ä¸
        verify_patch_simple()
        
        # æµ‹è¯•å¯¼å…¥
        try:
            from transformers import AutoProcessor
            print("âœ… å¯ä»¥æ­£å¸¸å¯¼å…¥ AutoProcessor")
        except Exception as e:
            print(f"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
    
    print("âœ¨ æµ‹è¯•å®Œæˆ")